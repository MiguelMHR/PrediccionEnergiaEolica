{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica 1 - Predicción Energía Eólica\n",
    "Autores:\n",
    "- Miguel Domínguez Gómez - 100451258\n",
    "- Eduardo Fernández Vega - 100472251  \n",
    "\n",
    "Enlace al repositorio:\n",
    "https://github.com/MiguelMHR/Practica1-PrediccionEnergia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Tabla de contenidos:\n",
    "1. [Requisitos](#1.-Requisitos)\n",
    "2. [Lectura](#2.-Lectura)\n",
    "3. [EDA](#3.-EDA)\n",
    "4. [Evaluación inner y outer](#4.-Evaluación-inner-y-outer) \n",
    "5. [Elección del mejor escalador](#5.-Elección-del-mejor-escalador)\n",
    "6. [Evaluación de los modelos](#6.-Evaluación-de-los-modelos)\n",
    "7. [Creación modelo final](#7.-Creación-modelo-final)\n",
    "8. [Transformación problema regresión a clasificación](#8.-Transformación-problema-regresión-a-clasificacion)\n",
    "9. [Uso de AI en nuestro proyecto](#9.-Uso-de-AI-en-nuestro-proyecto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Requisitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías necesarias para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold, TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.svm import SVR, SVC\n",
    "from time import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a leer el dataset usando la librería Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset\n",
    "wind_ava = pd.read_csv('./data/wind_ava.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se hará un análisis exploratorio de datos siguiento las cuestiones expuestas en el enunciado de la práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Preparación previa del dataset\n",
    "Como se expone en el punto **importante** de la práctica, debemos, antes de realizar el EDA simplificado, una limpieza de las columnas que no sean importantes. Las únicas que son relevantes son aquellas que tienen que ver con Sotavento:\n",
    "- **datetime**\n",
    "- **energy**\n",
    "- solo aquellas que tengan un \".13\" al final (**p54.162.13, p55.162.13, cape.13, etc**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para quedarme solo con las columnas que terminan por \".13\" o que sean \"energy\" o \"datetime\"\n",
    "columnas_a_mantener = [columna for columna in wind_ava.columns if columna.endswith('.13') or columna == 'energy' or columna == 'datetime']\n",
    "wind_ava = wind_ava[columnas_a_mantener]\n",
    "print(wind_ava.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Descripción general del dataset\n",
    "Para poder conocer ciertas características relevantes del dataset, como el número de instancias (filas) y característas (columnas) procederemos a usar diferentes funciones de Pandas con el dataset transformado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción de parámetros generales -> count, mean, std, min, 25%, 50%, 75%, max\n",
    "print(wind_ava.describe())\n",
    "\n",
    "# Número de filas y columnas del dataset\n",
    "print(\"\\n\")\n",
    "print(\"Número de filas: \", wind_ava.shape[0])\n",
    "print(\"Número de columnas: \", wind_ava.shape[1])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Para saber el tipo de variable de cada columna\n",
    "print(wind_ava.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, no existen valores nulos ya que el número de filas (4748) coincide con la cuenta de los valores no-nulos de cada columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ya se ha visto en el anterior apartado, no existen valores nulos como tal. Para asegurarnos, haremos lo siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para poder saber el número de valores faltantes:\n",
    "print(wind_ava.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, comprobaremos, como todos son números decimales, si por casualidad hay algún cero que no tengan sentido en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, comprobaremos, como todos son números decimales, si por casualidad hay algún cero que no tengan sentido en el dataset\n",
    "# Para ello, veremos el número de ceros que hay en cada columna\n",
    "print((wind_ava == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que en cape.13 hay bastantes valores que son cero pero, como esa variable tiene sentido que sea cero en determinados contextos, como en condiciones atmosféricas estables, se ha decidido mantener así"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Columnas constantes\n",
    "En este apartado se evaluará qué columnas son constantes para todos sus valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar las columnas que tienen un solo valor único (columnas constantes)\n",
    "constant_columns = wind_ava.columns[wind_ava.nunique() <= 1].tolist()\n",
    "print(constant_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, no existen columnas constantes, por lo que no se va a eliminar nada del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 ¿Regresión o clasificación?\n",
    "Directamente conociendo la naturaleza de la variable objetivo, la energía, se puede saber ante qué tipo de problema nos enfrentamos. Como la energía es una variable continua, nos encontramos ante un problema de **regresión**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Otras consideraciones: outliers\n",
    "Otro apartado del EDA que no se menciona en el enunciado y que creemos que es de vital importancia para realizar un buen análisis exploratorio es evaluar los valores lejanos, o outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1 Outliers con Histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos varios métodos de representación de los datos para poder observar los valores alejados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quitamos 'datetime' al no ser una columna numérica\n",
    "columna_excluida = 'datetime'\n",
    "plt.hist(wind_ava[wind_ava.columns.difference([columna_excluida])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que hay ciertos valores que se salen de la norma, aunque se verá más claro realizando los boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5.2 Outliers con Boxplot\n",
    "Para poder evaluar atributo a atributo, se procederá a hacer un boxplot de los 21 atributos (menos datetime, al no ser numérico y no tener outliers al ser un registro de las mediciones diarias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot para cada atributo y sacamos los outliers de cada uno\n",
    "outliers = []\n",
    "for attribute in wind_ava.columns.difference([columna_excluida]):\n",
    "    plt.boxplot(wind_ava[attribute])\n",
    "    plt.title(attribute)\n",
    "    plt.show()\n",
    "    Q1 = wind_ava[attribute].quantile(0.25)\n",
    "    Q3 = wind_ava[attribute].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers.append(wind_ava[(wind_ava[attribute] < lower_bound) | (wind_ava[attribute] > upper_bound)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como muestran los resultados, hay ciertos atributos que poseen bastantes outliers, otros que poseen algunos y hay otros atributos en los que es inexistente. Hace falta determinar si esos son ruido, para ser eliminados en futuros modelos para mejorar la predicción, o si son datos realmente significativos para el dataset. Al ser variables meteorológicas, cabe la posibilidad de que haya cierto fallo en la medición, pero al ser la metereología de una región algo tan cambiante, se cree que esa información debe prevalecer en el dataset, a pesar de poseer outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluación inner y outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se va a describir el proceso seguido para realizar tanto la evaluación inner como la outer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha decidido dividir el dataset en **train** y **test** de la siguiente forma, siguiendo el criterio, no exactamente, de *2/3 para train* y *1/3* *para* *test*:\n",
    "\n",
    "* *train:* 2005 al 2007 (**60%**)\n",
    "* *test:* 2008 y 2009 (**40%**)\n",
    "\n",
    "No se ha decidido añadir aleatoriedad a la selección de instancias a las particiones *train* y *test* ya que hay dependencia temporal en los datos. Es decir, no se pueden mezclar datos del 2005 con datos del 2009 ya que podrían afectar al aprendizaje del modelo. \n",
    "\n",
    "No se ha decidido seguir al 100% *2/3 para train* y *1/3* *para test* al querer dividir las particiones por años exactos.\n",
    "\n",
    "\n",
    "\n",
    "Por otro lado, dentro del *train*, se va a realizar un **ajuste de hiperparámetros** para la evaluacion inner, dividiendo *train*, siguiendo TimeSeriesSplit, con 2 splits, de la siguiente forma:\n",
    "\n",
    "* **Prueba #1**:\n",
    "  * *train_train:* 2005\n",
    "  * *train_validation: 2006*\n",
    "* **Prueba #2:**\n",
    "  * *train_train:* 2005 y 2006\n",
    "  * *train_validation:* 2007\n",
    "\n",
    "Se ha decidido usar TimeSeriesSplit para dividir *train* por la misma razón por la que no añadiamos aleatoriedad a la selección de instancias. Al trabajar con datos con dependencia temporal, es mejor usar TimeSeriesSplit. Además, se ha decidido usar GridSearch al ser el método de ajuste de hiper-parámetros óptimo (computacionalmente es costoso, pero da los mejores resultados)\n",
    "\n",
    "Los hiperparámetros que se van a ajustar dependen del modelo a usar y se comentarán en el punto 4\n",
    "\n",
    "\n",
    "Para la evaluación outer, se evaluará el rendimiento usando la partición *train* inicial y la partición *test* de 2008 y 2009, es decir, el dataset completo, usando los mejores hiperparámetros encontrados en la evaluación inner. \n",
    "\n",
    "\n",
    "Las **métricas** que se van a usar para evaluar el rendimiento a futuro van a ser:\n",
    "\n",
    "* **RMSE (Root mean squared error) :** muy recomendado como métrica de error\n",
    "* **Tiempo de ejecución :** es una variable relevante para poder ofrecer un modelo que pueda ejecutar en un tiempo razonable. También, se usará como medio de desempate si hay modelos que tienen errores muy parecidos.\n",
    "\n",
    "Aunque siempre se priorizará el modelo que tenga menos error, habrá una excepción. Si el tiempo de ejecución es infinitamente superior en uno de los dos modelos a comparar y poseen errores muy parecidos, se elegirá el que tenga menor tiempo de ejecución.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----  Selección inicial de X e Y  ----\n",
    "# X -> Todas las columnas menos 'datetime' y 'energy'\n",
    "# Y -> 'energy'\n",
    "X = wind_ava.loc[:,columnas_a_mantener[2:]]\n",
    "Y = wind_ava.energy\n",
    "\n",
    "# ----  División del dataset en Train-Test:  ----\n",
    "# Dividimos el dataset en entrenamiento del 2005 al 2007 y test del 2007 al 2009\n",
    "X_train = X.loc[wind_ava.datetime < '2008-01-01']\n",
    "X_test = X.loc[wind_ava.datetime >= '2008-01-01']\n",
    "Y_train = Y.loc[wind_ava.datetime < '2008-01-01']\n",
    "Y_test = Y.loc[wind_ava.datetime >= '2008-01-01']\n",
    "\n",
    "# ----  TimeSeriesSplit  ----\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Elección del mejor escalador\n",
    "Para elegir el mejor escalador, se hará varias pruebas usando KNN por omisión con 3-Fold cross validation, una por cada scaler:\n",
    "MinMax, Standard y Robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Si el método a usar posee random_state, usar 100451258 (mi NIA)\n",
    "\"\"\"\n",
    "\n",
    "# Establecemos la semilla aleatoria\n",
    "np.random.seed(100451258)\n",
    "\n",
    "# ----  Evaluación inner con 3-Fold CV  ----\n",
    "inner = KFold(n_splits=3, shuffle=True)\n",
    "# Diccionario para almacenar los resultados de la evaluación inner  ----\n",
    "inner_scores = {}\n",
    "\n",
    "# ----  1. KNN con StandardScaler  ----\n",
    "# Creamos el pipeline\n",
    "pipeline_std = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsRegressor())])\n",
    "# Evaluación inner\n",
    "scores_std = cross_val_score(pipeline_std, X_train, Y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['KNN con StandardScaler'] = -scores_std.mean()\n",
    "\n",
    "# ----  2. KNN con MinMaxScaler  ----\n",
    "# Creamos el pipeline\n",
    "pipeline_mm = Pipeline([('scaler', MinMaxScaler()), ('knn', KNeighborsRegressor())])\n",
    "# Evaluación inner\n",
    "scores_mm = cross_val_score(pipeline_mm, X_train, Y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['KNN con MinMaxScaler'] = -scores_mm.mean()\n",
    "\n",
    "# ----  3. KNN con RobustScaler  ----\n",
    "# Creamos el pipeline\n",
    "pipeline_rb = Pipeline([('scaler', RobustScaler()), ('knn', KNeighborsRegressor())])\n",
    "# Evaluación inner\n",
    "scores_rb = cross_val_score(pipeline_rb, X_train, Y_train, cv=inner, scoring='neg_root_mean_squared_error')\n",
    "inner_scores['KNN con RobustScaler'] = -scores_rb.mean()\n",
    "\n",
    "# ----  RESULTADOS FINALES  ----\n",
    "for name, score in inner_scores.items():\n",
    "    print(f\"{name}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, el mejor scaler y el que usaremos de ahora en adelante es StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluación de los modelos\n",
    "Se procederá a realizar la evaluación de los siguientes modelos.\n",
    "- **KNN**:\n",
    "  - Por omisión de hiperparámetros\n",
    "  - Por ajuste de hiperparámetros\n",
    "- **Árboles de decisión**\n",
    "  - Por omisión de hiperparámetros\n",
    "  - Por ajuste de hiperparámetros\n",
    "- **Regresión lineal**\n",
    "  - Normal : por omisión de hiperparámetros\n",
    "  - Lasso : por ajuste de hiperparámetros\n",
    "- **SVM**\n",
    "  - Por omisión de hiperparámetros\n",
    "  - Por ajuste de hiperparámetros\n",
    "- **Regresión Dummy**\n",
    "  - Por omisión de hiperparámetros\n",
    "\n",
    "Una vez se terminen las evaluaciones, se describirán las conclusiones alcanzadas en este apartado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de comenzar, debemos escalar los datos usando el **StandardScaler**, el mejor escalador hayado en el punto anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----  Estandarizacion de los datos:  ----\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.1 KNN por omisión de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# ----  1. KNN sin hiperparámetros  ----\n",
    "knn = KNeighborsRegressor()\n",
    "start = time()\n",
    "scores = cross_val_score(knn, X, Y, scoring='neg_root_mean_squared_error', cv=tscv) \n",
    "end = time()\n",
    "\n",
    "print(f\"MSRE: {scores.mean():.2f} ± {scores.std():.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1.2 KNN usando hiperparámetros\n",
    "Los hiperparámetros elegidos para KNN son los siguientes:\n",
    "- **n_neighbours** : número de vecinos\n",
    "- **weights** : método de ponderación\n",
    "  - uniform : todos los vecinos tienen el mismo peso\n",
    "  - distance : los vecinos más cercanos tienen más peso\n",
    "- **metric** : métrica de distancia de la cercanía de los puntos\n",
    "  - euclidean : distancia euclídea\n",
    "  - manhattan : distancia manhattan\n",
    "  - minkowski : distancia minkowski\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# 0. Elección de hiperparámetros\n",
    "knn_param = {\n",
    "    'n_neighbors': range(1, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric' : ['euclidean', 'manhattan', 'minkowski'],\n",
    "}\n",
    "\n",
    "# 1. Evaluación inner\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "gs_regr = GridSearchCV(knn, \n",
    "                       knn_param, \n",
    "                       scoring='neg_root_mean_squared_error', \n",
    "                       cv=tscv, \n",
    "                       n_jobs=-1, \n",
    "                       )\n",
    "# 2. Entrenamiento con la partición de entrenamiento\n",
    "start = time()\n",
    "gs_regr.fit(X_train, Y_train)\n",
    "end = time()\n",
    "best_hyperparams = gs_regr.best_params_\n",
    "rmse = -gs_regr.best_score_\n",
    "std = gs_regr.cv_results_['std_test_score'][gs_regr.best_index_]\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {best_hyperparams}\")\n",
    "print(f\"MSRE: {rmse:.2f} ± {std:.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.1 Árboles de decisión por omisión de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# ----  1. Árboles de decisión sin hiperparámetros  ----\n",
    "tree = DecisionTreeRegressor()\n",
    "start = time()\n",
    "scores = cross_val_score(tree, X, Y, scoring='neg_root_mean_squared_error', cv=tscv) \n",
    "end = time()\n",
    "\n",
    "print(f\"MSRE: {-scores.mean():.2f} ± {scores.std():.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2.2 Árboles de decisión por ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hiperparámetros que han sido elegidos son los siguientes:\n",
    "- **max_depth** : profundidad máxima\n",
    "- **min_samples_split** : número mínimo de instancias que debe de\n",
    "tener un nodo interno para ser subdividido\n",
    "- **min_samples_leaf** : número mínimo de instancias requeridas para que un nodo sea considerado como una hoja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# 0. Elección de hiperparámetros\n",
    "tree_param = {\n",
    "    'max_depth': range(2,16,2),\n",
    "    'min_samples_split': range(2,16,2),\n",
    "    'min_samples_leaf': range(2,16,2)\n",
    "}\n",
    "\n",
    "# 1. Evaluación inner\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "gs_regr = GridSearchCV(tree, \n",
    "                       tree_param, \n",
    "                       scoring='neg_root_mean_squared_error', \n",
    "                       cv=tscv, \n",
    "                       n_jobs=-1, \n",
    "                       )\n",
    "# 2. Entrenamiento con la partición de entrenamiento\n",
    "start = time()\n",
    "gs_regr.fit(X_train, Y_train)\n",
    "end = time()\n",
    "best_hyperparams = gs_regr.best_params_\n",
    "rmse = -gs_regr.best_score_\n",
    "std = gs_regr.cv_results_['std_test_score'][gs_regr.best_index_]\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {best_hyperparams}\")\n",
    "print(f\"MSRE: {rmse:.2f} ± {std:.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.1 Regresión lineal normal (solo omisión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# ----  1. Árboles de decisión sin hiperparámetros  ----\n",
    "reg_lin = LinearRegression()\n",
    "start = time()\n",
    "scores = cross_val_score(reg_lin, X, Y, scoring='neg_root_mean_squared_error', cv=tscv) \n",
    "end = time()\n",
    "print(f\"MSRE: {-scores.mean():.2f} ± {scores.std():.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2 Regresión Lasso (ajuste de hiperparámetros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha decidido ajustar el siguiente hiperparámetro:\n",
    "- **alpha** : controla la fuerza de la regularización en el modelo Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# 0. Elección de hiperparámetros de lasso\n",
    "lasso_param = {\n",
    "    \"alpha\": np.logspace(-2, 5, 75)\n",
    "}\n",
    "\n",
    "# 1. Evaluación inner\n",
    "lasso = Lasso()\n",
    "\n",
    "gs_regr = GridSearchCV(lasso, \n",
    "                       lasso_param, \n",
    "                       scoring='neg_root_mean_squared_error', \n",
    "                       cv=tscv, \n",
    "                       n_jobs=-1, \n",
    "                       )\n",
    "# 2. Entrenamiento con la partición de entrenamiento\n",
    "start = time()\n",
    "gs_regr.fit(X_train, Y_train)\n",
    "end = time()\n",
    "best_hyperparams = gs_regr.best_params_\n",
    "rmse = -gs_regr.best_score_\n",
    "std = gs_regr.cv_results_['std_test_score'][gs_regr.best_index_]\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {best_hyperparams}\")\n",
    "print(f\"MSRE: {rmse:.2f} ± {std:.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Máquina de soporte de vectores (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.4.1 SVM por omisión de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# ----  1. SVM sin hiperparámetros  ----\n",
    "svm = SVR()\n",
    "start = time()\n",
    "scores = cross_val_score(svm, X, Y, scoring='neg_root_mean_squared_error', cv=tscv) \n",
    "end = time()\n",
    "\n",
    "print(f\"MSRE: {-scores.mean():.2f} ± {scores.std():.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.4.2 SVM con ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hiperparámetros elegidos para ser ajustados son:\n",
    "- **C** : controla el equilibrio entre la maximización del margen y la minimización de la clasificación errónea\n",
    "- **epsilon** : controla la influencia de cada ejemplo de entrenamiento en el modelo\n",
    "- **kernel** : funciones de kernel para transformar los datos en un espacio de mayor dimensión donde sea más fácil encontrar un hiperplano de separación lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# 0. Elección de hiperparámetros\n",
    "svm_param = {\n",
    "    'C': [0.1, 1, 10, 100, 1000, 10000],\n",
    "    'epsilon': [0.1, 0.2, 0.3, 0.4],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# 1. Evaluación inner\n",
    "svm = SVR()\n",
    "\n",
    "gs_regr = GridSearchCV(svm, \n",
    "                       svm_param, \n",
    "                       scoring='neg_root_mean_squared_error', \n",
    "                       cv=tscv, \n",
    "                       n_jobs=-1, \n",
    "                       )\n",
    "# 2. Entrenamiento con la partición de entrenamiento\n",
    "start = time()\n",
    "gs_regr.fit(X_train, Y_train)\n",
    "end = time()\n",
    "best_hyperparams = gs_regr.best_params_\n",
    "rmse = -gs_regr.best_score_\n",
    "std = gs_regr.cv_results_['std_test_score'][gs_regr.best_index_]\n",
    "\n",
    "print(f\"Mejores hiperparámetros: {best_hyperparams}\")\n",
    "print(f\"MSRE: {rmse:.2f} ± {std:.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Regresor Dummy (solo por omision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# ----  1. SVM sin hiperparámetros  ----\n",
    "dummy = DummyRegressor()\n",
    "start = time()\n",
    "scores = cross_val_score(dummy, X, Y, scoring='neg_root_mean_squared_error', cv=tscv) \n",
    "end = time()\n",
    "\n",
    "print(f\"MSRE: {-scores.mean():.2f} ± {scores.std():.2f}\")\n",
    "print(\"Tiempo de ejecución: \" + str(end-start) + \" segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6 Conclusiones finales:\n",
    "Al evaluar todos los modelos siguiendo todo el proceso descrito en el apartado 2, se han logrado obtener varias conclusiones:\n",
    "- La utilización de hiperparámetros mejora considerablemente las predicciones, resultando en errores más bajos\n",
    "  - Además, al tener que probar con varios modelos mientras se realiza el ajuste, tanto el coste computacional como el tiempo de ejecución aumentan. Como la mayor importancia reside en un error menor de los modelos, este hecho no nos preocupa ya que los tiempos, igualmente, son relativamente bajos y permisibles.\n",
    "- El **mejor método básico** (sin ajuste de hiper parámetros) ha sido **árboles de decisión**\n",
    "- El **mejor método** global (tanto con ajuste como sin ajuste) obtenido ha sido **SVM con ajuste de hiperparámetros**. Ha sido el que más ha tardado en ejecutar, pero el que mejor resultado ha brindado\n",
    "- Por otro lado, los regresores dummy no han proporcionado mejores resultados que los métodos comentados anteriormente\n",
    "- Finalmente, existe una proporcionalidad visible entre el tiempo de ejecución y el error obtenido. A mayor tiempo de ejecución, menor error obtenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Construcción modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, una vez hemos obtenido el mejor modelo, SVM con hiperparámetros ('C': 1000, 'epsilon': 0.4, 'kernel': 'rbf'), se procederá a entrenar de nuevo el modelo usando los hiperparámetros obtenidos y **todos los datos**, es decir, teniendo en cuenta x_test. Además, se creará el modelo que hará las predicciones en otro ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100451258)\n",
    "\n",
    "# 0. Uso de hiperparámetros obtenidos\n",
    "svm_param = {\n",
    "    'C': 1000,\n",
    "    'epsilon': 0.4,\n",
    "    'kernel': 'rbf'\n",
    "}\n",
    "\n",
    "# 1. Entrenamiento con hiperparámetros de evaluación inner\n",
    "svm = SVR(**svm_param)\n",
    "\n",
    "# 2. Entrenamiento con la partición de entrenamiento\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "# 3. Evaluación outer del modelo\n",
    "Y_pred = svm.predict(X_test)\n",
    "mse = metrics.mean_squared_error(Y_test, Y_pred)\n",
    "print(\"RMSE: \", np.sqrt(mse))\n",
    "\n",
    "# 4. Construimos el modelo final con todos los datos sin hacer ajuste por hiperparámetros\n",
    "# Computacionalmente más asequible y sigue siendo válido\n",
    "svm.fit(X, Y)\n",
    "mse_total = metrics.mean_squared_error(Y, svm.predict(X))\n",
    "print(\"RMSE total: \", np.sqrt(mse_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, exportamos el modelo a un archivo .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./modelo_final.pkl\", \"wb\") as file:\n",
    "    pickle.dump(svm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Transformación a problema de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último apartado se resolverá el punto final del enunciado:\n",
    "1. se pide comprobar con el mejor modelo obtenido hasta el momento, si las predicciones para valores altos son peores que para valores bajos.\n",
    "   - cuando la energía sea menor que el tercer cuantil, se considerará clase “baja”, y cuando sea mayor, clase “alta”.\n",
    "2. se nos propone convertir el problema de regresión en uno de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que tienes el mejor modelo de regresión guardado en \"best_regression_model\"\n",
    "\n",
    "# Realizar predicciones con el mejor modelo de regresión\n",
    "predictions = svm.predict(X)\n",
    "\n",
    "# Añadir las predicciones al DataFrame\n",
    "wind_ava['predicted_energy'] = predictions\n",
    "\n",
    "# Calcular el tercer cuartil de la energía\n",
    "third_quantile = wind_ava['energy'].quantile(0.75)\n",
    "\n",
    "# Calcular el error relativo para valores altos y bajos\n",
    "err_rel_low = abs(wind_ava[wind_ava['energy'] <= third_quantile]['predicted_energy'] - wind_ava[wind_ava['energy'] <= third_quantile]['energy'])\n",
    "err_rel_high = abs(wind_ava[wind_ava['energy'] > third_quantile]['predicted_energy'] - wind_ava[wind_ava['energy'] > third_quantile]['energy'])\n",
    "\n",
    "print(\"Error relativo para valores bajos:\", err_rel_low.mean())\n",
    "print(\"Error relativo para valores altos:\", err_rel_high.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación problema de regresión en clasificación:\n",
    "# Crear una nueva columna para la variable objetivo con clases \"baja\" y \"alta\"\n",
    "wind_ava_clases = wind_ava\n",
    "wind_ava_clases['target_class'] = 'baja'\n",
    "wind_ava_clases.loc[wind_ava['energy'] > third_quantile, 'target_class'] = 'alta'\n",
    "\n",
    "# Dividir el DataFrame en características (X) y variable objetivo (y)\n",
    "X_clases = wind_ava_clases[wind_ava.columns.difference(['target_class','datetime','predicted_energy'])]\n",
    "Y_clases = wind_ava_clases['target_class']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train_clases = X_clases.loc[wind_ava.datetime < '2008-01-01']\n",
    "X_test_clases = X_clases.loc[wind_ava.datetime >= '2008-01-01']\n",
    "Y_train_clases = Y_clases.loc[wind_ava.datetime < '2008-01-01']\n",
    "Y_test_clases = Y_clases.loc[wind_ava.datetime >= '2008-01-01']\n",
    "\n",
    "# Entrenar un modelo de clasificación (por ejemplo, SVM)\n",
    "clf = SVC()\n",
    "clf.fit(X_train_clases, Y_train_clases)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test_clases)\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_test_clases, y_pred))\n",
    "print(metrics.classification_report(Y_test_clases, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Uso de AI en nuestro trabajo\n",
    "Para poder realizar este trabajo, se han usado, fundamentalmente, 2 AIs:\n",
    "- **ChatGPT** : Para dudas de caracter general, ya sean explicación de los hiperparámetros, definición del proceso de evaluación, información adicional a cerca del proceso de realización de un EDA e interpretaciones generales de los resultados.\n",
    "- **Github Copilot** : Ha sido la herramienta que más ha sido usada. Cuando se realizaban las evaluaciones, nossotros podíamos definir mediante un comentario, toda la creación del código en base a los requerimientos del comentario. Además, cuando nos saltaba un error en la ejecución, Copilot era nuestra guía para poder solventar los errores encontrados.\n",
    "\n",
    "Cabe mencionar que la gran mayoría de información y conocimientos han sido extraídos de los videos publicados en Aulaglobal y las diapositivas del curso. Han sido unos recursos que nos han ido guiando bastante, sobre todo, en el proceso de evaluación. Las cuestiones que se alejaban más del temario enseñado han podido ser resultas gracias a las AIs comentadas previamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
